{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13864f53",
      "metadata": {
        "id": "13864f53"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as neuralnet\n",
        "import torch.nn.functional as func\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "# tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74f7a631",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74f7a631",
        "outputId": "233188d3-c2b1-4e0e-d334-2e4f8c4ba34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# check for gpu availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path where dataset is found\n",
        "path = \"/content/drive/MyDrive/predicting music genres using cnn/Data/\"\n",
        "\n",
        "train_data_path = path + \"images_original/\"\n",
        "test_data_path = path + \"images_original_test/\"\n",
        "\n",
        "# resize image and convert the number of channels to 1 \n",
        "dataset = ImageFolder(train_data_path, transforms.Compose([transforms.Resize((30, 40)), \n",
        "                                                           transforms.ToTensor(), \n",
        "                                                           transforms.Grayscale(num_output_channels = 1)]))\n",
        "\n",
        "test_dataset = ImageFolder(test_data_path, transforms.Compose([transforms.Resize((30, 40)), \n",
        "                                                               transforms.ToTensor(), \n",
        "                                                               transforms.Grayscale(num_output_channels = 1)]))\n"
      ],
      "metadata": {
        "id": "fpvzVpZGwj9U"
      },
      "id": "fpvzVpZGwj9U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into batches to limit the amount of memory usage\n",
        "batch_size = 10\n",
        "val_size = 40\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size)\n",
        "test_dataloader = DataLoader(test_dataset)\n",
        "\n",
        "examples = iter(train_dataloader)\n",
        "example_data, example_targets = examples.next()"
      ],
      "metadata": {
        "id": "EL_J-O9X1XDV"
      },
      "id": "EL_J-O9X1XDV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_mean(input_array):\n",
        "  '''This function is used to find the mean of elements in an array'''\n",
        "  sum = 0\n",
        "  for i in input_array:\n",
        "    sum = sum + i\n",
        "  mean = sum/(len(input_array))\n",
        "  return mean\n",
        "\n",
        "def accuracy(outputs, lables):\n",
        "  '''This function computes the accuracy of the model on teh test set'''\n",
        "  _, preds = torch.max(outputs, dim = 1)\n",
        "  return torch.tensor(torch.sum(preds == labels).items() / len(preds))"
      ],
      "metadata": {
        "id": "7Bw9AcwF2XTZ"
      },
      "id": "7Bw9AcwF2XTZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network models\n",
        "# Baseline model - FeedForward Neural Network (FNN)\n",
        "class FeedForwarNet(neuralnet.Module):\n",
        "  def __init__(self, input_size, hidden_size, classes):\n",
        "    super(FeedForwardNet, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.layer1 = neuralnet.Linear(input_size, hidden_size) # input size 30*40\n",
        "    self.relu = neuralnet.ReLU()\n",
        "    self.layer2 = neuralnet.Linear(hidden_size, classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "      out = self.layer1(x)\n",
        "      out = self.relu(out)\n",
        "      out = self.layer2(out)\n",
        "      return out\n",
        "\n",
        "# Main model - Convolution Neural Network (CNN)\n",
        "\n",
        "class ConvNeuralNet(neuralnet.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNeuralNet, self).__init__()\n",
        "\n",
        "    self.conv1 = neuralnet.Conv2d(1, 60, kernel_size = 3) # 60\n",
        "    self.pool = neuralnet.MaxPool2d(2, 2)\n",
        "    self.conv2 = neuralnet.Conv2d(60, 80, kernel_size = 3)\n",
        "    self.conv3 = neurlanet.Conv2d(80, 150, kernel_size = 3)\n",
        "\n",
        "    self.fc1 = neuralnet.Linear(900, 450)\n",
        "    self.fc2 = neuralnet.Linear(450, 150)\n",
        "    self.fc3 = neuralnet.Linear(150, 10)\n",
        "\n",
        "    self.dropout = neuralnet.Dropout(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.pool(func.relu(self.conv1(x)))\n",
        "      x = self.pool(func.relu(self.conv2(x)))\n",
        "      x = self.pool(func.relu(self.conv3(x)))\n",
        "\n",
        "      x = torch.flatten(x, 1)\n",
        "      x = self.fc1(x)\n",
        "      x = func.relu(x)\n",
        "      x = self.fc2(x)\n",
        "      x = func.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc3(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "MZhJ8z-b3Kam"
      },
      "id": "MZhJ8z-b3Kam",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model hyperparameters\n",
        "# Feed Forward Neural Network input and hidden size\n",
        "input_size = 1200 # 30 * 40\n",
        "hidden_size = 1000 \n",
        "\n",
        "classes = 10\n",
        "\n",
        "learning_rate = 0.001\n",
        "weight_decay_value = 0\n",
        "num_epochs = 50\n",
        "opt_func = Adam\n",
        "loss_func = neuralnet.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "W6xmwggU_d5f"
      },
      "id": "W6xmwggU_d5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = []\n",
        "validation_losses = []\n",
        "accuracy_score_out = []\n",
        "\n",
        "# define model\n",
        "baseline_model = FeedForwardNet(input_size, hidden_size, classes).to(device)\n",
        "model = ConvNeuralNet().to(device)\n",
        "\n",
        "# tensor board\n",
        "writer.add_graph(baseline_model, example_data.reshape(-1, 30*40))\n",
        "writer.close()\n",
        "\n",
        "writer.add_graph(model, example_data)\n",
        "writer.close()\n"
      ],
      "metadata": {
        "id": "uZXYb1pDR7jj"
      },
      "id": "uZXYb1pDR7jj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, model_type):\n",
        "  val_losses = []\n",
        "  accuracy_scores = []\n",
        "\n",
        "  for batch in val_dataloader:\n",
        "    images, labels = batch\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    if model_type == \"FNN\":\n",
        "      images = images.reshape(-1, 30*40)\n",
        "\n",
        "    output = model(images)\n",
        "\n",
        "    val_loss = loss_func(output, labels)\n",
        "    accuracy_ = accuracy(output, labels)\n",
        "\n",
        "    val_losses.append(val_loss)\n",
        "    accuracy_scores.append(accuracy_)\n",
        "\n",
        "  val_loss_out = find_mean(val_losses)\n",
        "  val_losses.clear()\n",
        "  validation_losses_out.append(accuracy_score_out)\n",
        "\n",
        "  print('Epoch : ', epoch + 1, '\\t', 'loss :', val_loss_out)\n",
        "\n",
        "  def train_model(model, model_type):\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay_value)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_losses = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "      images, labels = batch\n",
        "\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      if model_type == \"FNN\":\n",
        "        images = images.reshape(-1, 30*40)\n",
        "\n",
        "        #forward pass\n",
        "        outputs = model(images)\n",
        "        train_loss = loss_func(outputs, lables)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss_out = find_mean(train_losses)\n",
        "    train_losses.clear()\n",
        "    trainign_losses.append(train_loss_out)\n",
        "    print(\"train_loss\", train_loss_out)\n",
        "\n",
        "    validate_model(model, model_type)"
      ],
      "metadata": {
        "id": "TLs6ovn0SkUB"
      },
      "id": "TLs6ovn0SkUB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Feed Forward Nerual Model\n",
        "for epoch in range(num_epochs):\n",
        "  train_model(baseline_model, \"FNN\")\n",
        "\n",
        "plt.plot(training_losses, label = 'training losses')\n",
        "plt.plot(validation_losses, label = 'validation loss')\n",
        "\n",
        "training_losses.clear()\n",
        "validation_losses.clear()\n",
        "\n",
        "plt.plot(accurary_scores_out, label = 'accuracy_score')\n",
        "accuracy_scores_out.clear()\n",
        "\n",
        "def test_model(model, model_type):\n",
        "  with torch.no_grad():\n",
        "    test_losses = []\n",
        "    accuracy_scores = []\n",
        "\n",
        "    test_loss_out = 0\n",
        "\n",
        "    accuracy_score_out = 0 \n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for data in test_dataloader:\n",
        "      images, labels = data\n",
        "      \n",
        "      images, labels = data\n",
        "\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      if model_type == \"FNN\":\n",
        "        images = images.reshape(-1, 30*40)\n",
        "\n",
        "      output = model(images)\n",
        "\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Accuracy of the network on test images: %d %%' % (\n",
        "          100 * correct / total))\n",
        "      \n",
        " test_model(baseline_model, \"FNN\")\n",
        " test_model(model, \"CNN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "4-V5ZGNdWfjl",
        "outputId": "fb1cef20-1669-4a4c-a9e5-ce4241c19976"
      },
      "id": "4-V5ZGNdWfjl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-63c3a6cd7be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train Feed Forward Nerual Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_epochs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SZE_GNpm080T"
      },
      "id": "SZE_GNpm080T"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvW5PuU2ysIo",
        "outputId": "5427be96-d6dc-4bb4-908b-3efb1c5d6065"
      },
      "id": "tvW5PuU2ysIo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "predict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}